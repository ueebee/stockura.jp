# æ‰‹å‹•Companyæƒ…å ±å–å¾—ã‚¿ã‚¹ã‚¯å®Ÿè¡Œæ‰‹é †æ›¸

## æ¦‚è¦

J-Quants APIã‹ã‚‰æ‰‹å‹•ã§ä¸Šå ´ä¼æ¥­æƒ…å ±ã‚’å–å¾—ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«åŒæœŸã™ã‚‹ãŸã‚ã®æ‰‹é †ã‚’èª¬æ˜ã—ã¾ã™ã€‚æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯**Dockerç’°å¢ƒå‰æ**ã§æ§‹ç¯‰ã•ã‚Œã¦ãŠã‚Šã€è¤‡æ•°ã®å®Ÿè¡Œæ–¹æ³•ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚

## å‰ææ¡ä»¶

### å¿…è¦ãªç’°å¢ƒ
- Docker & Docker Compose
- J-Quants API ã‚¢ã‚«ã‚¦ãƒ³ãƒˆï¼ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒ»ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼‰

### äº‹å‰æº–å‚™
```bash
# 1. Dockerç’°å¢ƒã®èµ·å‹•ï¼ˆå…¨ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•ï¼‰
docker-compose up -d

# 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆDockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§å®Ÿè¡Œï¼‰
docker-compose exec web alembic upgrade head

# 3. ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª
docker-compose ps
```

**èµ·å‹•ã•ã‚Œã‚‹ã‚µãƒ¼ãƒ“ã‚¹**:
- `web`: FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ (ãƒãƒ¼ãƒˆ8000)
- `worker`: Celeryãƒ¯ãƒ¼ã‚«ãƒ¼
- `db`: PostgreSQL (ãƒãƒ¼ãƒˆ5432)
- `redis`: Redis (ãƒãƒ¼ãƒˆ6379)
- `flower`: Celeryç›£è¦–ãƒ„ãƒ¼ãƒ« (ãƒãƒ¼ãƒˆ5555)

## å®Ÿè¡Œæ–¹æ³•ä¸€è¦§

### æ–¹æ³•1: ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã‚ˆã‚‹æ‰‹å‹•å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰

**æ¦‚è¦**: é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç”¨ã«ä½œæˆã•ã‚ŒãŸå°‚ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ç”¨ã—ãŸæœ€ã‚‚ç°¡å˜ãªæ–¹æ³•

**å®Ÿè¡Œæ‰‹é †**:
```bash
# Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
docker-compose exec web python test_jquants_sync.py
```

**å®Ÿè¡Œå†…å®¹**:
1. J-Quants APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
2. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆï¼ˆãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šç­‰ï¼‰
3. ä¼æ¥­ãƒ‡ãƒ¼ã‚¿åŒæœŸå®Ÿè¡Œï¼ˆå…¨ä¸Šå ´ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ï¼‰
4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢ãƒ†ã‚¹ãƒˆ

**ãƒ¡ãƒªãƒƒãƒˆ**:
- âœ… ä¸€é€£ã®å‡¦ç†ãŒè‡ªå‹•å®Ÿè¡Œã•ã‚Œã‚‹
- âœ… å„ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®çµæœç¢ºèªãŒå¯èƒ½
- âœ… ã‚¨ãƒ©ãƒ¼æ™‚ã®è©³ç´°ãªæƒ…å ±è¡¨ç¤º
- âœ… åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ã„

**å®Ÿè¡Œæ™‚é–“**: ç´„10-30åˆ†ï¼ˆä¼æ¥­æ•°ã«ã‚ˆã‚‹ï¼‰

### æ–¹æ³•2: Pythonç›´æ¥å®Ÿè¡Œ

**æ¦‚è¦**: Pythonã‚³ãƒ¼ãƒ‰ã‚’ç›´æ¥è¨˜è¿°ã—ã¦å®Ÿè¡Œã™ã‚‹æ–¹æ³•

**å®Ÿè¡Œæ‰‹é †**:
```bash
# 1. ä¸€æ™‚çš„ãªPythonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
docker-compose exec web bash -c 'cat > manual_sync.py << EOF
import asyncio
from datetime import date
from app.db.session import async_session_maker
from app.services.data_source_service import DataSourceService
from app.services.jquants_client import JQuantsClientManager
from app.services.company_sync_service import CompanySyncService

# èªè¨¼ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ã‚’ç™»éŒ²
from app.services.auth import StrategyRegistry
from app.services.auth.strategies.jquants_strategy import JQuantsStrategy
StrategyRegistry.register("jquants", JQuantsStrategy)

async def manual_sync():
    async with async_session_maker() as db:
        # ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        data_source_service = DataSourceService(db)
        client_manager = JQuantsClientManager(data_source_service)
        sync_service = CompanySyncService(db, data_source_service, client_manager)
        
        # åŒæœŸå®Ÿè¡Œï¼ˆJ-Quantsãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ID: 1ï¼‰
        sync_history = await sync_service.sync_companies(
            data_source_id=1,
            sync_type="full"
        )
        
        print(f"åŒæœŸå®Œäº† - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {sync_history.status}")
        print(f"ç·ä¼æ¥­æ•°: {sync_history.total_companies}")
        print(f"æ–°è¦: {sync_history.new_companies}, æ›´æ–°: {sync_history.updated_companies}")

# å®Ÿè¡Œ
asyncio.run(manual_sync())
EOF'

# 2. ä½œæˆã—ãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
docker-compose exec web python manual_sync.py

# 3. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
docker-compose exec web rm manual_sync.py
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- ğŸ”§ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŒå¯èƒ½
- ğŸ”§ å¿…è¦ãªéƒ¨åˆ†ã®ã¿å®Ÿè¡Œå¯èƒ½

### æ–¹æ³•3: Celeryã‚¿ã‚¹ã‚¯ã«ã‚ˆã‚‹å®Ÿè¡Œ

**æ¦‚è¦**: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã¨ã—ã¦å®Ÿè¡Œã™ã‚‹æ–¹æ³•ï¼ˆDockerã‚³ãƒ³ãƒ†ãƒŠã§æ—¢ã«èµ·å‹•æ¸ˆã¿ï¼‰

**ç¢ºèª**:
```bash
# Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ãŒèµ·å‹•ä¸­ã‹ç¢ºèª
docker-compose ps worker

# Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ã®ãƒ­ã‚°ç¢ºèª
docker-compose logs worker
```

**å®Ÿè¡Œæ‰‹é †**:
```bash
# Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§Celeryã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ
docker-compose exec web python -c "
from app.tasks.company_tasks import sync_companies_task

# ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«é€ä¿¡
result = sync_companies_task.delay(
    data_source_id=1,
    sync_date=None,  # Noneã§å½“æ—¥
    sync_type='full'
)

# çµæœã‚’å–å¾—ï¼ˆãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
sync_result = result.get()
print(f'åŒæœŸçµæœ: {sync_result}')
"
```

**Celeryç›£è¦–ãƒ„ãƒ¼ãƒ«ï¼ˆFlowerï¼‰**:
```bash
# ãƒ–ãƒ©ã‚¦ã‚¶ã§Celeryã‚¿ã‚¹ã‚¯ã®çŠ¶æ³ã‚’ç›£è¦–
# http://localhost:5555 ã«ã‚¢ã‚¯ã‚»ã‚¹
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- ğŸš€ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
- ğŸ“Š é€²æ—ç®¡ç†ãŒå¯èƒ½
- ğŸ”„ ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ã‚ã‚Š

### æ–¹æ³•4: REST APIçµŒç”±ã§ã®å®Ÿè¡Œ

**æ¦‚è¦**: FastAPIçµŒç”±ã§HTTP APIã¨ã—ã¦å®Ÿè¡Œï¼ˆDockerã‚³ãƒ³ãƒ†ãƒŠã§æ—¢ã«èµ·å‹•æ¸ˆã¿ï¼‰

**ç¢ºèª**:
```bash
# FastAPIã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ä¸­ã‹ç¢ºèª
docker-compose ps web

# FastAPIã‚µãƒ¼ãƒãƒ¼ã®ãƒ­ã‚°ç¢ºèª
docker-compose logs web

# APIãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª
curl http://localhost:8000/health
```

**å®Ÿè¡Œæ‰‹é †**:
```bash
# APIçµŒç”±ã§åŒæœŸå®Ÿè¡Œ
curl -X POST "http://localhost:8000/api/v1/companies/sync" \
  -H "Content-Type: application/json" \
  -d '{
    "data_source_id": 1,
    "sync_type": "full"
  }'
```

**API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**:
```bash
# ãƒ–ãƒ©ã‚¦ã‚¶ã§APIä»•æ§˜ã‚’ç¢ºèª
# http://localhost:8000/docs ã«ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆSwagger UIï¼‰
# http://localhost:8000/redoc ã«ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆReDocï¼‰
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- ğŸŒ Web UIã‹ã‚‰å®Ÿè¡Œå¯èƒ½
- ğŸ“¡ å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã®å‘¼ã³å‡ºã—å¯èƒ½

## ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±

### J-Quantsãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®š
ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ID `1` ãŒJ-Quants APIã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚

**è¨­å®šç¢ºèªæ–¹æ³•**:
```bash
# Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ç¢ºèª
docker-compose exec db psql -U postgres -d stockura -c "
SELECT id, name, data_source_type, api_base_url, is_active 
FROM data_sources 
WHERE data_source_type = 'jquants';
"
```

## åŒæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è©³ç´°

### sync_type ã‚ªãƒ—ã‚·ãƒ§ãƒ³
- **`"full"`**: å…¨ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨åŒæœŸï¼ˆæ¨å¥¨ï¼‰
- **`"incremental"`**: å·®åˆ†åŒæœŸï¼ˆå®Ÿè£…äºˆå®šï¼‰

### å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
- **åˆå›**: `"full"`ã§å…¨ãƒ‡ãƒ¼ã‚¿åŒæœŸ
- **æ—¥æ¬¡**: `"full"`ã§æœ€æ–°ãƒ‡ãƒ¼ã‚¿æ›´æ–°
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ **: `"incremental"`ã§å·®åˆ†æ›´æ–°ï¼ˆå°†æ¥å®Ÿè£…ï¼‰

## å–å¾—ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿

### ä¼æ¥­åŸºæœ¬æƒ…å ±
- éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ï¼ˆ4æ¡ï¼‰
- ä¼šç¤¾åï¼ˆæ—¥æœ¬èªãƒ»è‹±èªï¼‰
- æ¥­ç¨®åˆ†é¡ï¼ˆ17æ¥­ç¨®ãƒ»33æ¥­ç¨®ï¼‰
- å¸‚å ´åŒºåˆ†
- è¦æ¨¡åŒºåˆ†
- ä¿¡ç”¨åŒºåˆ†

### ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿
- 17æ¥­ç¨®ãƒã‚¹ã‚¿ãƒ¼ï¼ˆ18ç¨®é¡ï¼‰
- 33æ¥­ç¨®ãƒã‚¹ã‚¿ãƒ¼ï¼ˆ34ç¨®é¡ï¼‰
- å¸‚å ´ãƒã‚¹ã‚¿ãƒ¼ï¼ˆ10ç¨®é¡ï¼‰

## ã‚¨ãƒ©ãƒ¼å¯¾å‡¦æ³•

### ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨ãã®å¯¾å‡¦

#### 1. J-Quants APIèªè¨¼ã‚¨ãƒ©ãƒ¼
**ã‚¨ãƒ©ãƒ¼**: `Authentication failed`

**å¯¾å‡¦æ³•**:
```bash
# èªè¨¼æƒ…å ±ã‚’ç¢ºèª
docker-compose exec db psql -U postgres -d stockura -c "SELECT * FROM data_sources WHERE id = 1;"

# å¿…è¦ã«å¿œã˜ã¦èªè¨¼æƒ…å ±ã‚’æ›´æ–°
docker-compose exec db psql -U postgres -d stockura -c "
UPDATE data_sources 
SET config = jsonb_set(config, '{email}', '\"your-email@example.com\"')
WHERE id = 1;
"
```

#### 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼
**ã‚¨ãƒ©ãƒ¼**: `Connection refused`

**å¯¾å‡¦æ³•**:
```bash
# Dockerã‚³ãƒ³ãƒ†ãƒŠã®çŠ¶æ…‹ç¢ºèª
docker-compose ps

# PostgreSQLã‚³ãƒ³ãƒ†ãƒŠã®å†èµ·å‹•
docker-compose restart postgres
```

#### 3. ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼
**ã‚¨ãƒ©ãƒ¼**: `Rate limit exceeded`

**å¯¾å‡¦æ³•**:
- ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†å®Ÿè¡Œ
- J-Quantsã®ãƒ—ãƒ©ãƒ³ã‚’ç¢ºèª
- ãƒªãƒˆãƒ©ã‚¤é–“éš”ã‚’èª¿æ•´

#### 4. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼
**ã‚¨ãƒ©ãƒ¼**: `Memory error`

**å¯¾å‡¦æ³•**:
```bash
# Dockerã®ãƒ¡ãƒ¢ãƒªåˆ¶é™ã‚’æ‹¡å¼µ
# docker-compose.ymlã‚’ç·¨é›†ã—ã¦mem_limitã‚’è¿½åŠ 
```

## ç›£è¦–ãƒ»ç¢ºèªæ–¹æ³•

### åŒæœŸçŠ¶æ³ã®ç¢ºèª
```bash
# æœ€æ–°ã®åŒæœŸå±¥æ­´ã‚’ç¢ºèª
docker-compose exec db psql -U postgres -d stockura -c "
SELECT 
    id, sync_date, sync_type, status, 
    total_companies, new_companies, updated_companies,
    started_at, completed_at, error_message
FROM company_sync_history 
ORDER BY started_at DESC 
LIMIT 5;
"
```

### ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
```bash
# ä¼æ¥­æ•°ã®ç¢ºèª
docker-compose exec db psql -U postgres -d stockura -c "
SELECT COUNT(*) as total_companies FROM companies WHERE is_active = true;
"

# å¸‚å ´åˆ¥ä¼æ¥­æ•°
docker-compose exec db psql -U postgres -d stockura -c "
SELECT m.name as market_name, COUNT(*) as company_count
FROM companies c
JOIN market_masters m ON c.market_code = m.code
WHERE c.is_active = true
GROUP BY m.name, m.display_order
ORDER BY m.display_order;
"

# æ¥­ç¨®åˆ¥ä¼æ¥­æ•°ï¼ˆ17æ¥­ç¨®ï¼‰
docker-compose exec db psql -U postgres -d stockura -c "
SELECT s.name as sector_name, COUNT(*) as company_count
FROM companies c
JOIN sector17_masters s ON c.sector17_code = s.code
WHERE c.is_active = true
GROUP BY s.name, s.display_order
ORDER BY s.display_order;
"
```

### ãƒ­ã‚°ã®ç¢ºèª
```bash
# Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°
docker-compose logs -f web

# Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ­ã‚°
docker-compose logs -f worker

# å…¨ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ­ã‚°
docker-compose logs -f

# PostgreSQLãƒ­ã‚°
docker-compose logs -f db

# Redisãƒ­ã‚°
docker-compose logs -f redis
```

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ™‚ã®æ¨å¥¨è¨­å®š
```python
# ãƒãƒƒãƒã‚µã‚¤ã‚ºã®èª¿æ•´
BATCH_SIZE = 1000  # ä¸€åº¦ã«å‡¦ç†ã™ã‚‹ä¼æ¥­æ•°

# åŒæ™‚æ¥ç¶šæ•°ã®åˆ¶é™
MAX_CONCURRENT_REQUESTS = 5  # J-Quants APIã¸ã®åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
```

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ´»ç”¨
```python
# Redisã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æœ‰åŠ¹æ´»ç”¨
USE_CACHE = True
CACHE_TTL = 3600  # 1æ™‚é–“
```

## ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ³¨æ„äº‹é …

### èªè¨¼æƒ…å ±ã®ç®¡ç†
- J-Quants APIã®èªè¨¼æƒ…å ±ã¯ç’°å¢ƒå¤‰æ•°ã§ç®¡ç†
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å¹³æ–‡ã§ä¿å­˜ã—ãªã„
- å®šæœŸçš„ãªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å¤‰æ›´ã‚’æ¨å¥¨

### ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡
- APIå®Ÿè¡Œæ¨©é™ã®é©åˆ‡ãªè¨­å®š
- ãƒ­ã‚°ç›£è¦–ã®å®Ÿæ–½
- ç•°å¸¸ãªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œçŸ¥

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### å®Œå…¨ãƒªã‚»ãƒƒãƒˆæ‰‹é †
```bash
# 1. ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã®å…¨å‰Šé™¤
docker-compose exec db psql -U postgres -d stockura -c "TRUNCATE companies, company_sync_history RESTART IDENTITY;"

# 2. Redisã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¯ãƒªã‚¢
docker-compose exec redis redis-cli FLUSHDB

# 3. å†åŒæœŸå®Ÿè¡Œ
docker-compose exec web python test_jquants_sync.py
```

### ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
```bash
# å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„é•åã®ãƒã‚§ãƒƒã‚¯
docker-compose exec db psql -U postgres -d stockura -c "
SELECT c.code, c.company_name
FROM companies c
LEFT JOIN market_masters m ON c.market_code = m.code
WHERE c.market_code IS NOT NULL AND m.code IS NULL;
"

# é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
docker-compose exec db psql -U postgres -d stockura -c "
SELECT code, COUNT(*) as count
FROM companies
GROUP BY code
HAVING COUNT(*) > 1;
"
```

## å®šæœŸå®Ÿè¡Œã®è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

### Crontabã§ã®å®šæœŸå®Ÿè¡Œ
```bash
# ãƒ›ã‚¹ãƒˆãƒã‚·ãƒ³ã®crontabã‚’ç·¨é›†
crontab -e

# å¹³æ—¥ã®18æ™‚ã«è‡ªå‹•å®Ÿè¡Œï¼ˆDockerçµŒç”±ï¼‰
0 18 * * 1-5 cd /path/to/stockura.jp && docker-compose exec -T web python test_jquants_sync.py > logs/daily_sync.log 2>&1
```

### Celery Beatã§ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œ
```python
# app/core/celery_config.py
CELERYBEAT_SCHEDULE = {
    'daily-company-sync': {
        'task': 'app.tasks.company_tasks.daily_company_sync',
        'schedule': crontab(hour=18, minute=0, day_of_week='1-5'),  # å¹³æ—¥18æ™‚
        'args': ([1],)  # J-Quantsãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ID
    },
}
```

## ã¾ã¨ã‚

**Dockerç’°å¢ƒå‰æ**ã§ã®æ‰‹å‹•Companyæƒ…å ±å–å¾—ã®æœ€ã‚‚ç°¡å˜ã§æ¨å¥¨ã•ã‚Œã‚‹æ–¹æ³•ã¯ã€**æ–¹æ³•1ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ**ã§ã™ï¼š

```bash
# 1. Dockerç’°å¢ƒèµ·å‹•
docker-compose up -d

# 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
docker-compose exec web alembic upgrade head

# 3. Companyæƒ…å ±åŒæœŸå®Ÿè¡Œ
docker-compose exec web python test_jquants_sync.py
```

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ï¼š
- âœ… æ¥ç¶šãƒ†ã‚¹ãƒˆã‹ã‚‰å®Ÿéš›ã®åŒæœŸã¾ã§ä¸€è²«ã—ã¦å®Ÿè¡Œ
- âœ… è©³ç´°ãªé€²æ—è¡¨ç¤ºã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- âœ… çµæœã®åˆ†ã‹ã‚Šã‚„ã™ã„è¡¨ç¤º
- âœ… Dockerç’°å¢ƒã§å®‰å…¨ã«å®Ÿè¡Œå¯èƒ½

**å®Ÿè¡Œæ™‚é–“**: åˆå›ã¯å…¨ä¸Šå ´ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ï¼ˆç´„3,000-4,000ç¤¾ï¼‰ã®å–å¾—ã®ãŸã‚10-30åˆ†ç¨‹åº¦

**ç›£è¦–ãƒ„ãƒ¼ãƒ«**:
- Celeryç›£è¦–: http://localhost:5555 (Flower)
- APIä»•æ§˜: http://localhost:8000/docs (Swagger UI)
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³: http://localhost:8000