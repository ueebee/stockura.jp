#!/usr/bin/env python
"""Docker ç’°å¢ƒã§ã® Redis Sync æ©Ÿèƒ½ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
import os
import sys
import time
import asyncio
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ Python ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime) s] %(levelname) s: %(message) s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


class DockerRedisSyncTest:
    """Docker ç’°å¢ƒã§ã® Redis Sync çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    def __init__(self):
        self.test_results = {
            "diagnosis": {},
            "schedule_creation": {},
            "event_verification": {},
            "execution_history": {},
            "overall_status": "pending"
        }
        
    async def run_diagnosis(self):
        """è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("=" * 80)
        logger.info("1. è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œ")
        logger.info("=" * 80)
        
        try:
            # è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
            import subprocess
            result = subprocess.run(
                ["docker", "compose", "exec", "-T", "app", "python", "scripts/diagnose_redis_sync_docker.py"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                logger.info("âœ… è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
                
                # è¨ºæ–­çµæœã® JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
                diagnosis_file = Path(__file__).parent / "redis_sync_diagnosis.json"
                if diagnosis_file.exists():
                    with open(diagnosis_file, 'r', encoding='utf-8') as f:
                        diagnosis_data = json.load(f)
                        
                    # çµæœã‚’è§£æ
                    env_ok = all(
                        v.get("is_set", False) 
                        for k, v in diagnosis_data["environment_vars"].items() 
                        if isinstance(v, dict) and k.startswith("CELERY_BEAT_REDIS_SYNC")
                    )
                    redis_ok = all(
                        v.get("status") == "connected" 
                        for v in diagnosis_data["redis_connection"].values()
                        if isinstance(v, dict)
                    )
                    pubsub_ok = diagnosis_data["pubsub_test"].get("status") == "success"
                    
                    self.test_results["diagnosis"] = {
                        "status": "success",
                        "environment_vars_ok": env_ok,
                        "redis_connection_ok": redis_ok,
                        "pubsub_ok": pubsub_ok
                    }
                    
                    logger.info(f"  ç’°å¢ƒå¤‰æ•°: {'âœ…' if env_ok else 'âŒ'}")
                    logger.info(f"  Redis æ¥ç¶š: {'âœ…' if redis_ok else 'âŒ'}")
                    logger.info(f"  Pub/Sub: {'âœ…' if pubsub_ok else 'âŒ'}")
                else:
                    logger.warning("è¨ºæ–­çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    self.test_results["diagnosis"]["status"] = "warning"
            else:
                logger.error(f"è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚¨ãƒ©ãƒ¼: {result.stderr}")
                self.test_results["diagnosis"]["status"] = "error"
                
        except Exception as e:
            logger.error(f"è¨ºæ–­å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results["diagnosis"]["status"] = "error"
            
    async def test_schedule_creation_and_event(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆã¨ã‚¤ãƒ™ãƒ³ãƒˆç™ºè¡Œã®ãƒ†ã‚¹ãƒˆ"""
        logger.info("\n" + "=" * 80)
        logger.info("2. ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆã¨ã‚¤ãƒ™ãƒ³ãƒˆç¢ºèª")
        logger.info("=" * 80)
        
        try:
            import aiohttp
            
            # API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
            api_base = os.environ.get("API_BASE", "http://localhost:8000")
            url = f"{api_base}/api/v1/schedules"
            
            # ãƒ†ã‚¹ãƒˆç”¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿
            schedule_data = {
                "name": f"redis_sync_test_{int(time.time())}",
                "task_name": "fetch_listed_info_task",
                "cron_expression": "0 0 * * *",  # æ¯æ—¥ 0 æ™‚
                "description": "Redis Sync çµ±åˆãƒ†ã‚¹ãƒˆ",
                "enabled": True,
                "task_params": {
                    "period_type": "custom",
                    "from_date": "2024-08-06",
                    "to_date": "2024-08-06"
                }
            }
            
            # Redis ã‚¤ãƒ™ãƒ³ãƒˆãƒ¢ãƒ‹ã‚¿ãƒ¼ã‚’èµ·å‹•
            monitor_process = await asyncio.create_subprocess_exec(
                "docker", "compose", "exec", "-T", "app", "python", "scripts/monitor_redis_events.py",
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            # å°‘ã—å¾…æ©Ÿã—ã¦ãƒ¢ãƒ‹ã‚¿ãƒ¼ã‚’æº–å‚™
            await asyncio.sleep(2)
            
            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆ
            logger.info("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆä¸­...")
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=schedule_data) as response:
                    if response.status == 200:
                        result = await response.json()
                        schedule_id = result["id"]
                        logger.info(f"âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆæˆåŠŸ (ID: {schedule_id})")
                        
                        self.test_results["schedule_creation"] = {
                            "status": "success",
                            "schedule_id": schedule_id
                        }
                        
                        # ã‚¤ãƒ™ãƒ³ãƒˆãŒç™ºè¡Œã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ
                        await asyncio.sleep(3)
                        
                        # ãƒ¢ãƒ‹ã‚¿ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†
                        monitor_process.terminate()
                        await monitor_process.wait()
                        
                        # ãƒ¢ãƒ‹ã‚¿ãƒ¼ã®å‡ºåŠ›ã‚’ç¢ºèª
                        stdout, stderr = await monitor_process.communicate()
                        output = stdout.decode('utf-8')
                        
                        if "schedule_created" in output and schedule_id in output:
                            logger.info("âœ… Redis ã‚¤ãƒ™ãƒ³ãƒˆã®ç™ºè¡Œã‚’ç¢ºèª")
                            self.test_results["event_verification"] = {
                                "status": "success",
                                "event_received": True
                            }
                        else:
                            logger.warning("âŒ Redis ã‚¤ãƒ™ãƒ³ãƒˆãŒç¢ºèªã§ãã¾ã›ã‚“")
                            self.test_results["event_verification"] = {
                                "status": "failure",
                                "event_received": False
                            }
                            
                        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼šã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‰Šé™¤
                        delete_url = f"{url}/{schedule_id}"
                        async with session.delete(delete_url) as del_response:
                            if del_response.status == 204:
                                logger.info("âœ… ãƒ†ã‚¹ãƒˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                    else:
                        error_text = await response.text()
                        logger.error(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {error_text}")
                        self.test_results["schedule_creation"]["status"] = "error"
                        
        except Exception as e:
            logger.error(f"ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results["schedule_creation"]["status"] = "error"
            self.test_results["event_verification"]["status"] = "error"
            
    async def check_celery_beat_logs(self):
        """Celery Beat ã®ãƒ­ã‚°ã‚’ç¢ºèª"""
        logger.info("\n" + "=" * 80)
        logger.info("3. Celery Beat ãƒ­ã‚°ã®ç¢ºèª")
        logger.info("=" * 80)
        
        try:
            import subprocess
            
            # Celery Beat ã®ãƒ­ã‚°ã‚’å–å¾—
            result = subprocess.run(
                ["docker", "compose", "logs", "celery-beat", "--tail=50"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                logs = result.stdout
                
                # é‡è¦ãªãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèª
                critical_messages = {
                    "Redis Sync is ENABLED": False,
                    "Redis subscriber thread started": False,
                    "Subscribed to Redis channel": False,
                    "Received schedule event": False,
                    "Triggering immediate schedule sync": False
                }
                
                for message in critical_messages:
                    if message in logs:
                        critical_messages[message] = True
                        logger.info(f"âœ… '{message}' ãŒç¢ºèªã•ã‚Œã¾ã—ãŸ")
                    else:
                        logger.warning(f"âŒ '{message}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        
                # çµæœã‚’è¨˜éŒ²
                all_ok = all(critical_messages.values())
                self.test_results["celery_beat_logs"] = {
                    "status": "success" if all_ok else "partial",
                    "messages_found": critical_messages
                }
                
                if not all_ok:
                    logger.info("\n æœ€æ–°ã® Celery Beat ãƒ­ã‚°ï¼ˆæŠœç²‹ï¼‰:")
                    logger.info("-" * 40)
                    for line in logs.split('\n')[-20:]:
                        if any(keyword in line for keyword in ["Redis", "sync", "schedule", "CELERY"]):
                            logger.info(f"  {line}")
            else:
                logger.error("Celery Beat ãƒ­ã‚°ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                self.test_results["celery_beat_logs"] = {"status": "error"}
                
        except Exception as e:
            logger.error(f"ãƒ­ã‚°ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results["celery_beat_logs"] = {"status": "error"}
            
    def generate_summary(self):
        """ãƒ†ã‚¹ãƒˆçµæœã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        logger.info("\n" + "=" * 80)
        logger.info("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        logger.info("=" * 80)
        
        # å„ãƒ†ã‚¹ãƒˆã®çµæœã‚’ç¢ºèª
        all_success = True
        
        for test_name, result in self.test_results.items():
            if test_name == "overall_status":
                continue
                
            if isinstance(result, dict) and result.get("status") == "success":
                logger.info(f"âœ… {test_name}: æˆåŠŸ")
            else:
                logger.warning(f"âŒ {test_name}: å¤±æ•—ã¾ãŸã¯è­¦å‘Š")
                all_success = False
                
        self.test_results["overall_status"] = "success" if all_success else "failure"
        
        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        output_file = Path(__file__).parent / "docker_redis_sync_test_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)
            
        logger.info(f"\n ãƒ†ã‚¹ãƒˆçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
        
        if all_success:
            logger.info("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        else:
            logger.warning("\nâš ï¸  ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
    async def run_all_tests(self):
        """ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("Docker Redis Sync çµ±åˆãƒ†ã‚¹ãƒˆ")
        logger.info("=" * 80)
        
        try:
            # 1. è¨ºæ–­ã‚’å®Ÿè¡Œ
            await self.run_diagnosis()
            
            # 2. ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆã¨ã‚¤ãƒ™ãƒ³ãƒˆç¢ºèª
            await self.test_schedule_creation_and_event()
            
            # 3. Celery Beat ãƒ­ã‚°ç¢ºèª
            await self.check_celery_beat_logs()
            
            # 4. ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
            self.generate_summary()
            
        except Exception as e:
            logger.error(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    tester = DockerRedisSyncTest()
    await tester.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())